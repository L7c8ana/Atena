{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width: 150px\" src=\"cbpf_logo.png\">\n",
    "\n",
    "<font size=\"5\"> Deep Learning Dissolution Predictor\n",
    "    \n",
    "This is Beta V0.1 version of Neural Network classifier for Dissolution prediction.</font>\n",
    "<font size=\"2\">\n",
    "    \n",
    "This solution was developed by the Brazilian Center for Physics Research (CBPF) AI team.\n",
    "Authors: Bernardo M. Fraga, Luciana O. Dias, Clécio De Bom and CBPF-CENPES collaboration team.\n",
    "    \n",
    "**Contact:** debom@cbpf.br</font>\n",
    "\n",
    "<font size=\"2\">\n",
    "Cooperation Agreement (TC) # 2017/00485-5\n",
    "named: Metodologias Petrofísicas do poro ao poço por Imagens e Inteligência Artificial\n",
    "between  CBPF  and  PETROBRAS/CENPES. \n",
    "    \n",
    "**PI:** Marcio P. de Albuquerque\n",
    "\n",
    "Please do not remove this disclaimer.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para rodar somente as predições de facies de dissolução de uma rede já treinada.\n",
    "Os pesos da rede podem ser salvos com o callback `ModelCheckpoint` do notebook de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os, copy, sys\n",
    "sys.path.insert(0, os.path.abspath('BoreholeTools'))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy import interp\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.interpolate import interp1d\n",
    "from keras import losses\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import utils\n",
    "from SlidingDataGenerator import SlidingDataGenerator\n",
    "from BoreholeImporter import Data\n",
    "from BoreholeProcessingTools import CropData\n",
    "from utils import yesnoquestion, uniqueStr, divideblocksize, takeClosest, findChangeIntervals, cm_analysis, ismember\n",
    "import seaborn as sbr\n",
    "import pandas as pd\n",
    "from data_loader import load_dataClass\n",
    "import matplotlib\n",
    "import deepnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__currentPath__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obter os dados. `MakeChannels` controla se os 3 tipos de imagens (original, log10 e filtro gaussiano) serão geradas. Para a rede pré-treinada, deixar como `True`\n",
    "### Lembrar de trocar o diretório!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeChannels = True\n",
    "data_dirSave = \"/home/dados4T/DeepDissolutionClass/dataJC\"\n",
    "\n",
    "data_dirIMGW1 = os.path.join(data_dirSave, \"W1_5315-5738m_AMP_RAW.csv\")\n",
    "data_dirClassW1 = os.path.join(data_dirSave, \"W1_5315-5738m_Facies_Olinto.csv\")\n",
    "\n",
    "data_norm = load_dataClass(data_dirIMG=data_dirIMGW1, data_dirClass=data_dirClassW1, data_dirSave=data_dirSave, MakeChannels=MakeChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar os 3 filtros, obter as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = data_norm[\"Acoustic\"][:,:,0]\n",
    "log10 = data_norm[\"Acoustic\"][:,:,1]\n",
    "gauss = data_norm['Acoustic'][:,:,2]\n",
    "\n",
    "X = [log10, gauss]\n",
    "YLab = data_norm[\"FDISSOL\"]\n",
    "YLevels = list(np.unique(YLab))\n",
    "YNum = list(map(int, YLab))\n",
    "Y = tf.keras.utils.to_categorical(YNum, num_classes=3)\n",
    "n_classes = len(YLevels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração dos parâmetros. \n",
    "Window size deve ser a mesma do treino. A rede já enviada foi treinada com `window_size=41`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=41\n",
    "img_channels = 1\n",
    "__M__ = np.shape(X[0])[0]\n",
    "bsize = 64\n",
    "input_sizes = [(img_channels, window_size, np.shape(x)[1]) for x in X]\n",
    "weight_for_0 = (1 / np.sum(Y[:,0]))*(Y.shape[0])/3.0\n",
    "weight_for_1 = (1 / np.sum(Y[:,1]))*(Y.shape[0])/3.0\n",
    "weight_for_2 = (1 / np.sum(Y[:,2]))*(Y.shape[0])/3.0\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar o modelo e usar os pesos treinados.\n",
    "O arquivo *Model_ws41_bs64_loggauss_resnet50* contém os pesos da rede já treinada. Depois de criado o modelo, inserimos os pesos na rede. Para carregar outra rede já treinada, mudar o arquivo dos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepnets.ResnetBuilder.build_resnet_50(input_sizes, n_classes)\n",
    "model.load_weights('./results/models/Model_ws41_bs64_loggauss_resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegar os índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdxs,valIdxs,testIdxs = divideblocksize(__M__,100,0.99,0.01,0.0,\n",
    "                                                     overlapsize=window_size,display=False,silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazer as predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_sliding(x=X, batch_size=bsize, sliding_window=window_size, indexes=trainIdxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_data = dict()\n",
    "auc = dict()\n",
    "for i in range(n_classes):\n",
    "    roc_data[i] = metrics.roc_curve(YTrueTest, preds[:,i], pos_label=i)#, sample_weight=np.array([class_weight[i]] * preds.shape[0]))\n",
    "    auc[i] = metrics.auc(roc_data[i][0], roc_data[i][1])\n",
    "\n",
    "f, ax = plt.subplots(figsize=[9,6])\n",
    "ax.plot(roc_data[0][0], roc_data[0][1], 'k-', label='class 0, AUC = {:4.2f}'.format(auc[0]))\n",
    "ax.plot(roc_data[1][0], roc_data[1][1], 'b-', label='class 1, AUC = {:4.2f}'.format(auc[1]))\n",
    "ax.plot(roc_data[2][0], roc_data[2][1], 'r-', label='class 2, AUC = {:4.2f}'.format(auc[2]))\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrueTest = [YNum[ii] for ii in trainIdxs]\n",
    "cm_test = cm_analysis(y_true=YTrueTest,\n",
    "                                 y_pred=[np.argmax(p) for i,p in enumerate(preds)],\n",
    "                                 filename=os.path.join(__currentPath__,'results','ConfMatrix_Test_w1_2'),\n",
    "                                 classes=YLevels,\n",
    "                                 labels=range(len(YLevels)),\n",
    "                                 figsize=(12,12),\n",
    "                                 cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
