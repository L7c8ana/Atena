{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autokeras\n",
    "# !pip install PyQt5\n",
    "# !pip install scikit-image\n",
    "# !apt-get update\n",
    "# !apt-get install ffmpeg libsm6 libxext6  -y\n",
    "# !pip install seaborn\n",
    "# !pip install laspy==1.5.0\n",
    "# !pip install lasio\n",
    "import lasio\n",
    "import random, os, copy, sys\n",
    "import os\n",
    "import laspy\n",
    "import pickle\n",
    "import autokeras as ak\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "import seaborn as sbr\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPU:0']\n",
      "0\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# G = [\"8\", \"9\"]\n",
    "G = [\"0\"]\n",
    "stringGPUs = []\n",
    "for i in G:\n",
    "    GPS = \"GPU:\" + i\n",
    "    stringGPUs.append(GPS)\n",
    "\n",
    "\n",
    "print(stringGPUs)\n",
    "print(\",\".join(G))\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \",\".join(G)\n",
    "\n",
    "if len(G) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=stringGPUs)#, cross_device_ops=tf.distribute.NcclAllReduce())\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=stringGPUs[0])\n",
    "\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirSave = \"/tf/DataProjects/NewBoreholeMarcio\"\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(data_dirSave,\"EntregaPetroDissolucao\"))\n",
    "from data_loader import load_dataClassNewMarcioTrain#, load_dataClass2Borehole\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_resultsPKL(results, path = None):\n",
    "    with open(path,'wb') as f:\n",
    "        pickle.dump(results,f)\n",
    "\n",
    "\"\"\" function to load results \"\"\"\n",
    "def load_resultsPKL(path=None):\n",
    "    with open(path,'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/DataProjects/NewBoreholeMarcio/W5_AMP.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /tf/DataProjects/NewBoreholeMarcio/W5_AMP.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/DataProjects/NewBoreholeMarcio/ResultInferenceWS41GaussCustomResnetWellW3/PlotsInference/ResultsInference_W3.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01128285260d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mPathSaveFinals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dirSave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ResultInferenceWS\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"GaussCustomResnetWell\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mIDx1Borehole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdirPltsPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPathSaveFinals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PlotsInference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdictResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_resultsPKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirPltsPred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ResultsInference_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mIDx1Borehole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdata_dirIMG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata_dirClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1c32c46b5bcb>\u001b[0m in \u001b[0;36mload_resultsPKL\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\"\"\" function to load results \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_resultsPKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/DataProjects/NewBoreholeMarcio/ResultInferenceWS41GaussCustomResnetWellW3/PlotsInference/ResultsInference_W3.pkl'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.join(data_dirSave,\"EntregaPetroDissolucao\"))\n",
    "from data_loader import load_dataClassNewMarcioTrain#, load_dataClass2Borehole \n",
    "\n",
    "IDx1Borehole = \"W3\"\n",
    "Blind = False\n",
    "window_size = 41\n",
    "data_dirSave = \"/tf/DataProjects/NewBoreholeMarcio\"\n",
    "PathSaveFinals = os.path.join(data_dirSave, \"ResultInferenceWS\" + str(window_size) + \"GaussCustomResnetWell\" + IDx1Borehole)\n",
    "dirPltsPred = os.path.join(PathSaveFinals, \"PlotsInference\")\n",
    "dictResults = load_resultsPKL(path = os.path.join(dirPltsPred,'ResultsInference_' + IDx1Borehole + '.pkl'))\n",
    "data_dirIMG = []\n",
    "data_dirClass = []\n",
    "start_time = time.time()\n",
    " \n",
    "data_dirIMG.append(os.path.join(data_dirSave, dictResults[\"File_IMG_Well\"]))\n",
    "print(data_dirIMG)\n",
    "\n",
    "if not Blind:\n",
    "    data_dirClass.append(os.path.join(data_dirSave, dictResults[\"File_Class_Well\"]))\n",
    "    try:\n",
    "        dpC = pd.read_csv(data_dirClass[0], delimiter=\";\")\n",
    "    except:\n",
    "        dpC = pd.read_csv(data_dirClass[0], delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    DepthNoInterp = dpC[\"Depth\"]\n",
    "    ClassNoInterp = dpC[\"faciesdissolucao\"]\n",
    "else:\n",
    "    data_dirClass = None\n",
    "data_norm = load_dataClassNewMarcioTrain(data_dirIMG=data_dirIMG, data_dirClass=data_dirClass, data_dirSave=data_dirSave,\n",
    "                               MakeChannels=True, dataPred=False, DataTrain=None, LabelWell=IDx1Borehole)\n",
    "print(\"Time load data :\")   \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueStr(l):\n",
    "    u = list(set(l))\n",
    "    i = []\n",
    "    for c in l:\n",
    "        i.append(int(c))\n",
    "        \n",
    "    return u,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = data_norm['Acoustic'][:,:,0] # image normalize\n",
    "DepthInterp = data_norm['Depth']\n",
    "ClassInterp = data_norm['FDISSOL']\n",
    "# print(ClassInterp)\n",
    "Ylevels, Ynum = uniqueStr(ClassInterp)\n",
    "# print(ClassInterp[0:10])\n",
    "# print(Ynum[0:10])\n",
    "n_classes = len(Ylevels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sbr.set_style(\"darkgrid\")\n",
    "df = pd.DataFrame({'labels':ClassInterp})\n",
    "ax = sbr.countplot(data=df,y='labels',saturation=0.55,edgecolor=None,linewidth=2,label=None, ax=ax, order=df['labels'].value_counts().index)\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[1,0]\n",
    "    y=p.get_bbox().get_points()[:,1]\n",
    "    ax.annotate('{:.0f}'.format(x), (x+1000, y.mean()),\n",
    "            ha='left', va='center') # set the alignment of the text\n",
    "plt.ticklabel_format(style='sci',axis='x',scilimits=(0,0))\n",
    "ax.set_ylabel('Classes')\n",
    "fig.savefig(\"BarPlotNumberClass.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classifications without interpolation and interpolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ['g', 'r', 'b']\n",
    "# intv = 500\n",
    "CP = np.zeros((DepthInterp.shape[0], n_classes))\n",
    "for y in range(n_classes):\n",
    "    CP[:, y] = DepthInterp\n",
    "\n",
    "\n",
    "PlotsVert = True\n",
    "if PlotsVert:\n",
    "    inic = 4000\n",
    "    fin = 5000\n",
    "    fig = plt.figure(figsize=(32, 32))#constrained_layout=True)\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax1.imshow(orig[inic:fin, :], cmap=\"gray\")\n",
    "    # ax1.set_ylim(ax1.get_ylim()[::-1])  # invertendo axes y\n",
    "    # ax1.set_yticks(np.arange(fin,fin+inic,1))\n",
    "    # ax1.set_ylim([DepthInterp[inic], DepthInterp[fin]])\n",
    "    ax1.set_yticklabels(DepthInterp[inic:fin])\n",
    "    ax1.axes.get_xaxis().set_visible(False)\n",
    "    ax2.axis('off')\n",
    "    ax3.axis('off')\n",
    "    CPR = CP[inic:fin,:]\n",
    "    YNN = ClassInterp[inic:fin]\n",
    "    for g, j in zip(np.arange(0,len(YNN),1), YNN):\n",
    "        ax2.plot(np.arange(0,n_classes,1), CPR[g,:], cl[int(j)])\n",
    "#         ax2.set_yticklabels(CP[inic:fin,0])\n",
    "    DD = np.where((np.float32(DepthNoInterp) >=  np.float32(DepthInterp[inic])) & (np.float32(DepthNoInterp) <=  np.float(DepthInterp[fin])))\n",
    "    for g, l, j in zip(np.arange(0,len(DepthNoInterp[DD[0]]),1),DepthNoInterp[DD[0]], ClassNoInterp[DD[0]]):\n",
    "        ax3.plot(np.arange(0,n_classes,1), [l,l,l] , cl[j])\n",
    "#         ax3.set_yticklabels(DepthNoInterp[DD[0]])\n",
    "#         ax3.set_yticklabels(CP[inic:fin,0])\n",
    "\n",
    "\n",
    "#         ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n",
    "#                    borderaxespad=0.)  # , loc='upper left', borderaxespad=0.\n",
    "#         # ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=1.)#, loc='upper left', borderaxespad=0.\n",
    "\n",
    "#     fig.savefig(os.path.join(dirPltsPred,\"ShowDataREAL_PRED_ModelW1W2_\" + h + str(inic) + \"-\" + str(fin) + \".png\"))\n",
    "#             plt.close()\n",
    "\n",
    "#     print(\"Plots Saved in: \" + os.path.join(dirPltsPred,\"ShowDataREAL_PRED_ModelW1W2_\" + h + str(inic) + \"-\" + str(fin) + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare real and predicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ['g', 'r', 'b']\n",
    "# intv = 500\n",
    "CP = np.zeros((DepthInterp.shape[0], n_classes))\n",
    "for y in range(n_classes):\n",
    "    CP[:, y] = DepthInterp\n",
    "\n",
    "# print(dictResults[\"Pred_Per_Depth_Intep\"])\n",
    "\n",
    "PredInterp = dictResults[\"Pred_Per_Depth_Intep\"]\n",
    "\n",
    "PlotsVert = True\n",
    "if PlotsVert:\n",
    "    inic = 4000\n",
    "    fin = 5000\n",
    "    fig = plt.figure(figsize=(32, 32))#constrained_layout=True)\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax1.imshow(orig[inic:fin, :], cmap=\"gray\")\n",
    "    # ax1.set_ylim(ax1.get_ylim()[::-1])  # invertendo axes y\n",
    "    # ax1.set_yticks(np.arange(fin,fin+inic,1))\n",
    "    # ax1.set_ylim([DepthInterp[inic], DepthInterp[fin]])\n",
    "    ax1.set_yticklabels(DepthInterp[inic:fin])\n",
    "    ax1.axes.get_xaxis().set_visible(False)\n",
    "    ax2.axis('off')\n",
    "    ax3.axis('off')\n",
    "    CPR = CP[inic:fin,:]\n",
    "    YNN = ClassInterp[inic:fin]\n",
    "    PP = PredInterp[inic:fin]\n",
    "    for g, j, p in zip(np.arange(0,len(YNN),1), YNN, PP):\n",
    "        ax2.plot(np.arange(0,n_classes,1), CPR[g,:], cl[int(j)])\n",
    "        if int(p) > 0:\n",
    "            ax3.plot(np.arange(0,n_classes,1), CPR[g,:], cl[int(p)-1])\n",
    "\n",
    "#     fig.savefig(os.path.join(dirPltsPred,\"ShowDataREAL_PRED_ModelW1W2_\" + h + str(inic) + \"-\" + str(fin) + \".png\"))\n",
    "#             plt.close()\n",
    "\n",
    "#     print(\"Plots Saved in: \" + os.path.join(dirPltsPred,\"ShowDataREAL_PRED_ModelW1W2_\" + h + str(inic) + \"-\" + str(fin) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /usr/local/lib/python3.6/dist-packages/laspy/file.py\n",
    "# !pip install laspy==1.7.0\n",
    "# !/usr/bin/python3 -m pip install --upgrade pip\n",
    "# !pip list laspy\n",
    "!pip install laspy==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasio.examples\n",
    "import lasio\n",
    "from datetime import datetime\n",
    "from sys import stdout\n",
    "las = lasio.LASFile()\n",
    "las.well.DATE = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "depths = np.zeros((80))\n",
    "las.add_curve('POCO', depths, unit='str')\n",
    "las.add_curve('TOPO', depths, descr='m')\n",
    "las.add_curve('BASE', depths, descr='m')\n",
    "las.add_curve('PROPRIEDADE', depths, descr='int')\n",
    "las.add_curve('VALOR', depths, descr='int')\n",
    "las.add_curve('CLASSIFICACAO', depths, descr='int')\n",
    "print(las.header)\n",
    "\n",
    "# del las.header[\"Well\"][\"Other\"]\n",
    "\n",
    "las.write('ModeloRelatorioLAS.las', version=2)\n",
    "las = lasio.read(\"ModeloRelatorioLAS.las\")\n",
    "print(las.sections.keys())\n",
    "dflas = las.df()\n",
    "print(\"####################################################################\")\n",
    "print(dflas)\n",
    "# las.write(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
